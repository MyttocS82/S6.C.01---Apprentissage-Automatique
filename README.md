# ğŸ½ï¸ Analyse intelligente des avis Yelp

> Analyse de donnÃ©es, classification de sentiments et prÃ©diction de notes Ã  partir du dataset Yelp â€” avec Machine Learning, Deep Learning et IA gÃ©nÃ©rative.

---

## ğŸ“‹ Table des matiÃ¨res

- [PrÃ©sentation du projet](#prÃ©sentation-du-projet)
- [Structure du projet](#structure-du-projet)
- [PrÃ©requis & Installation](#prÃ©requis--installation)
- [Ordre d'exÃ©cution](#ordre-dexÃ©cution)
- [Partie A â€” Analyse de donnÃ©es](#partie-a--analyse-de-donnÃ©es)
- [Partie B â€” ModÃ¨les de prÃ©diction](#partie-b--modÃ¨les-de-prÃ©diction)
- [Utilisation de main.py](#utilisation-de-mainpy)
- [ModÃ¨les disponibles](#modÃ¨les-disponibles)
- [IA GÃ©nÃ©rative](#ia-gÃ©nÃ©rative)

---

## ğŸ“Œ PrÃ©sentation du projet

Ce projet porte sur l'analyse et la classification automatique des avis de la plateforme **Yelp**. Il comprend deux grandes parties :

- **Partie A** : Analyse exploratoire des donnÃ©es (EDA) Ã  partir des fichiers `business`, `users`, `reviews` et `photos`.
- **Partie B** : ModÃ¨les de prÃ©diction de la **polaritÃ©** (positif / neutre / nÃ©gatif) et du **score** (1 Ã  5 Ã©toiles) des avis, en combinant plusieurs reprÃ©sentations textuelles et mÃ©thodes d'apprentissage.

---

## ğŸ—‚ï¸ Structure du projet

```
.
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                        # Fichiers JSON bruts du dataset Yelp
â”‚       â”œâ”€â”€ yelp_academic_dataset_business.json
â”‚       â”œâ”€â”€ yelp_academic_dataset_user.json
â”‚       â”œâ”€â”€ yelp_academic_dataset_review.json
â”‚       â””â”€â”€ yelp_academic_dataset_photo.json
â”‚
â”œâ”€â”€ models/                         # ModÃ¨les entraÃ®nÃ©s (gÃ©nÃ©rÃ©s par init.py)
â”‚   â”œâ”€â”€ model_bow_nb_rating.pkl
â”‚   â”œâ”€â”€ vectorizer_bow_nb_rating.pkl
â”‚   â”œâ”€â”€ model_reglog_rating.pkl
â”‚   â”œâ”€â”€ vectorizer_reglog_rating.pkl
â”‚   â”œâ”€â”€ model_svc_rating.pkl
â”‚   â”œâ”€â”€ vectorizer_svc_rating.pkl
â”‚   â”œâ”€â”€ model_mlp_rating.keras
â”‚   â”œâ”€â”€ model_cnn_rating.keras
â”‚   â”œâ”€â”€ model_bert_rating/          # ModÃ¨le BERT fine-tunÃ© (rating)
â”‚   â”œâ”€â”€ model_bert_sentiment/       # ModÃ¨le BERT fine-tunÃ© (sentiment)
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ results/
â”‚   â””â”€â”€ figures/                    # Graphiques gÃ©nÃ©rÃ©s par data_visualizations.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â””â”€â”€ load_data.py            # Chargement des datasets Yelp
â”‚   â”œâ”€â”€ ia/
â”‚   â”‚   â”œâ”€â”€ classification_zero_shot.py   # Classification zero-shot (LLM)
â”‚   â”‚   â””â”€â”€ classification_few_shot.py    # Classification few-shot (LLM)
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ machine_learning/       # ModÃ¨les ML classiques
â”‚   â”‚   â”œâ”€â”€ deep_learning/          # ModÃ¨les MLP & CNN
â”‚   â”‚   â””â”€â”€ transformers/           # ModÃ¨les BERT
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ utils.py                # Fonctions utilitaires (ex: create_label_review)
â”‚   â”œâ”€â”€ visualization/
â”‚   â”‚   â””â”€â”€ data_visualizations.py  # âš ï¸ Ã€ exÃ©cuter en premier
â”‚   â”œâ”€â”€ init.py                     # âš ï¸ Ã€ exÃ©cuter en deuxiÃ¨me
â”‚   â””â”€â”€ main.py                     # Interface principale
```

---

## âš™ï¸ PrÃ©requis & Installation

### Environnement Python recommandÃ©

```bash
python >= 3.10
```

### Installation des dÃ©pendances

```bash
pip install -r requirements.txt
```

> Les principales librairies utilisÃ©es sont : `pandas`, `numpy`, `matplotlib`, `scikit-learn`, `tensorflow` / `keras`, `transformers` (HuggingFace), `torch`.

---

## ğŸš€ Ordre d'exÃ©cution

> âš ï¸ **Il est impÃ©ratif de respecter l'ordre suivant avant d'utiliser `main.py`.**

### Ã‰tape 1 â€” Analyse exploratoire des donnÃ©es

```bash
python src/visualization/data_visualizations.py
```

Ce script charge les datasets Yelp et gÃ©nÃ¨re les **visualisations** dans `results/figures/`.

---

### Ã‰tape 2 â€” EntraÃ®nement des modÃ¨les

```bash
python src/init.py
```

Ce script parcourt tous les fichiers de `src/models/` et entraÃ®ne les modÃ¨les **qui ne sont pas encore prÃ©sents** dans `models/`. Les modÃ¨les dÃ©jÃ  gÃ©nÃ©rÃ©s sont automatiquement ignorÃ©s.

---

### Ã‰tape 3 â€” Interface de prÃ©diction

```bash
python src/main.py
```

---

## ğŸ“Š Partie A â€” Analyse de donnÃ©es

Le script `data_visualizations.py` produit les analyses suivantes :

| # | Analyse | Visualisation |
|---|---------|---------------|
| 1 | Distribution des ratings dans le dataset reviews | Histogramme |
| 2 | Longueur des avis dans le dataset reviews | Histogramme |
| 3 | Longueur des avis par rapport aux notes | Boxplot |
| 4 | Lien entre le nombre d'avis d'un business et sa note moyenne | Scatter plot (Ã©chelle log) |
| 5 | Notes moyennes par rapport au nombre d'avis des utilisateurs | Scatter plot (Ã©chelle log) |
| 6 | Longueur des avis : utilisateurs expÃ©rimentÃ©s vs tous les utilisateurs | Boxplot |
| 7 | Longueur moyenne des reviews par classe de note (1 â†’ 5) | Bar chart |

> Les figures sont sauvegardÃ©es automatiquement dans `results/figures/` au format PNG (rÃ©solution 500 dpi).

### RÃ¨gle de labellisation de la polaritÃ©

| Score | Label |
|-------|-------|
| > 3   | âœ… Positif |
| = 3   | ğŸ˜ Neutre  |
| < 3   | âŒ NÃ©gatif |

---

## ğŸ¤– Partie B â€” ModÃ¨les de prÃ©diction

### TÃ¢ches

| TÃ¢che | Description | Sortie |
|-------|-------------|--------|
| **PrÃ©diction de polaritÃ©** | Classifier un avis en positif / neutre / nÃ©gatif | `-1`, `0`, `1` |
| **PrÃ©diction du score** | PrÃ©dire la note attribuÃ©e (1 Ã  5 Ã©toiles) | `1`, `2`, `3`, `4`, `5` |

---

### 1. ReprÃ©sentations textuelles

| ReprÃ©sentation | Description |
|----------------|-------------|
| **Bag-of-Words (BoW)** | Sac de mots simples |
| **TF-IDF** | PondÃ©ration terme-frÃ©quence / frÃ©quence inverse |
| **Embeddings BERT** | ReprÃ©sentations contextuelles issues de BERT prÃ©-entraÃ®nÃ© |

---

### 2. MÃ©thodes d'apprentissage

| CatÃ©gorie | ModÃ¨les |
|-----------|---------|
| **Machine Learning classique** | Naive Bayes (BoW), RÃ©gression Logistique (TF-IDF), SVM (TF-IDF) |
| **Deep Learning** | MLP, CNN avec couche TextVectorization intÃ©grÃ©e |
| **Transformers** | BERT fine-tunÃ© (TFAutoModelForSequenceClassification) |

---

### 3. Conventions de nommage des fichiers modÃ¨les

```
model_<type>_<tÃ¢che>.pkl/.keras    â†’  modÃ¨le entraÃ®nÃ©
vectorizer_<type>_<tÃ¢che>.pkl      â†’  vectorizer associÃ© (BoW / TF-IDF)
model_bert_<tÃ¢che>/                â†’  dossier modÃ¨le BERT
bert_<tÃ¢che>_model_tokenizer/      â†’  dossier tokenizer BERT
```

**Exemples :**
```
model_bow_nb_rating.pkl
vectorizer_bow_nb_rating.pkl
model_cnn_sentiment.keras
model_bert_rating/
bert_rating_model_tokenizer/
```

---

## ğŸ–¥ï¸ Utilisation de main.py

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   Outil de classification de texte   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  1. Analyser une ligne de texte (mÃ©thode IA)
  2. Analyser un fichier CSV     (modÃ¨le entraÃ®nÃ©)
  3. Quitter
```

### Option 1 â€” Analyse d'un texte via IA gÃ©nÃ©rative

Permet d'analyser un texte en entrant directement une phrase ou une revue.  
Deux mÃ©thodes disponibles :
- **Zero-shot classification** : le LLM prÃ©dit directement le sentiment sans exemple.
- **Few-shot classification** : le LLM reÃ§oit quelques exemples avant de prÃ©dire.

### Option 2 â€” Analyse d'un fichier CSV via un modÃ¨le entraÃ®nÃ©

1. SÃ©lectionner un modÃ¨le parmi ceux disponibles dans `models/`
2. Fournir le chemin vers un fichier CSV
3. SÃ©lectionner la colonne textuelle Ã  analyser
4. Les prÃ©dictions sont affichÃ©es (20 premiÃ¨res lignes) puis il est proposÃ© de :
   - ğŸ’¾ Sauvegarder les rÃ©sultats dans un nouveau CSV (`*_predictions.csv`)
   - ğŸ“Š Ã‰valuer les prÃ©dictions par rapport Ã  une colonne rÃ©elle (accuracy, rapport de classification, matrice de confusion)
   - Les deux
   - Ne rien faire

---

## ğŸ§  IA GÃ©nÃ©rative

### Zero-shot

```
src/ia/classification_zero_shot.py
Fonction : zero_shot_predict_sentiment(text: str) -> str
```

Le LLM reÃ§oit uniquement le texte de la revue et produit une prÃ©diction de sentiment **sans donnÃ©es d'entraÃ®nement**.

### Few-shot

```
src/ia/classification_few_shot.py
Fonction : few_shot_predict_sentiment(text: str) -> str
```

Le LLM reÃ§oit quelques exemples annotÃ©s (positif / nÃ©gatif / neutre) avant de prÃ©dire le sentiment du texte fourni.

### Aspect-Based Sentiment Analysis (ABSA)

Le LLM produit une **sortie structurÃ©e** identifiant :
- les aspects mentionnÃ©s dans la revue (ex: nourriture, service, prix)
- le sentiment associÃ© Ã  chacun d'eux (positif / nÃ©gatif)

---

## ğŸ“ Dataset Yelp

Ce projet utilise le [Yelp Open Dataset](https://www.yelp.com/dataset).

| Fichier | Contenu | EntrÃ©es |
|---------|---------|---------|
| `yelp_academic_dataset_business.json` | Informations sur les Ã©tablissements | ~150 346 |
| `yelp_academic_dataset_user.json` | Profils utilisateurs | ~558 095 |
| `yelp_academic_dataset_review.json` | Avis textuels avec notes | ~1 000 000 |
| `yelp_academic_dataset_photo.json` | Photos associÃ©es aux Ã©tablissements | â€” |

> âš ï¸ Les fichiers de donnÃ©es ne sont **pas inclus** dans ce dÃ©pÃ´t. TÃ©lÃ©chargez-les depuis le site officiel Yelp et placez-les dans `data/raw/`.

---

## ğŸ‘¨â€ğŸ’» Auteur
**LAM ClÃ©ment** //
**LE VELLY Malek** //
**MASSAT Diego** //
**MICHELON Scott**

Module : `S6.C.01 - Apprentissage Automatique` - BUT Informatique 3 (AGED)
